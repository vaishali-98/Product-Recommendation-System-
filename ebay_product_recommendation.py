# -*- coding: utf-8 -*-
"""Ebay_Product_Recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O_Oz0lcaPzuugx6zt-azNUFog7rMOZ2l
"""

from IPython.display import Image
Image(filename ="image.jpeg", width=500, height=300)

# General imports
from collections import Counter
import pandas as pd
import numpy as np
import warnings
warnings.simplefilter('ignore')
import seaborn as sns
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import LabelEncoder
import requests
import urllib
import cv2
import re
from io import BytesIO
from PIL import Image
import requests, os
from os import path
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from scipy.sparse import hstack
from sklearn.metrics import pairwise_distances
from sklearn.model_selection import train_test_split
from tensorflow.keras import regularizers 
from keras.layers.core import Dropout
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from wordcloud import WordCloud
from tensorflow.keras.applications import vgg16
from tensorflow.keras.preprocessing.image import load_img,img_to_array
from tensorflow.keras.models import Model
from tensorflow.keras.applications.imagenet_utils import preprocess_input
import os
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity
from tensorflow.keras.models import load_model # to save the model
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers, losses
from tensorflow.random import set_seed
from sklearn.metrics import confusion_matrix

# Load data set
data1=pd.read_csv("Final_Cleaned data.csv")

data=data1.head(330)

data

data=data.reset_index()
data=data.rename(columns={"index":"PID"})
data.head(5)

# Checking the unique observations, datatype & null values for every feature
d = {"Feature":[i for i in data.columns]    ,"Nunique" :data.nunique().values ,'Type' : data.dtypes.values, "No: of nulls" : data.isnull().sum() }
description = pd.DataFrame(data = d)
description

data.describe()

def product_join(name):
    """
    This functions takes apparel type and returns product name joined with a space
  
    """
    return " ".join(t for t in data[data["output"]==name].product_name)

# Load the mask images
shoe_mask = np.array(Image.open(path.join("images_note/shoe.jpeg")))
shirt_mask = np.array(Image.open(path.join("images_note/shirt.jpeg")))
bag_mask = np.array(Image.open(path.join("images_note/bag.jpeg")))
watch_mask = np.array(Image.open(path.join("images_note/watch.jpeg")))
phone_mask = np.array(Image.open(path.join("images_note/phone.jpeg")))
earphone_mask = np.array(Image.open(path.join("images_note/earphone.jpeg")))
laptop_mask = np.array(Image.open(path.join("images_note/laptop.jpeg")))
pants_mask = np.array(Image.open(path.join("images_note/pants.jpeg")))
ring_mask = np.array(Image.open(path.join("images_note/ring.jpeg")))
necklace_mask = np.array(Image.open(path.join("images_note/necklace.jpeg")))
anklet_mask = np.array(Image.open(path.join("images_note/anklet.jpeg")))
list_masks = [shoe_mask, shirt_mask, bag_mask, watch_mask, phone_mask, earphone_mask, laptop_mask, pants_mask, ring_mask, necklace_mask, anklet_mask] 
list_name=["shoes", "shirts", "bags", "watches", "phone","earphones", "laptop", "pants", "ring", "necklace", "anklet" ]

for i in range(len(list_masks)):
    wordcloud = WordCloud(background_color="white",  mask=list_masks[i]).generate(product_join(list_name[i]))
    plt.figure(figsize=[5,5])
    plt.imshow(wordcloud, interpolation="bilinear")
    plt.axis("off")
    plt.show()

pd.DataFrame(data['output'].value_counts())

# Creating a plot to check class distribution
plt.figure(figsize=(12,7))# Creating an empty plot 
count_classes = pd.value_counts(data['output'], sort = True)
ax=count_classes.plot(kind = 'bar', rot=0)
plt.title("Apparel categories distribution")
plt.xlabel("Class")
plt.ylabel("Frequency")
for p in ax.patches:
      ax.annotate('{}'.format(p.get_height()),(p.get_x()+0.2,p.get_height()+6)) # Adding the count above the bars
plt.show()

def display_img(url):
    """
    This functions takes the image url and return the picture of the image
    """
    # we get the url of the apparel and download it
    response = requests.get(url)
    img = Image.open(BytesIO(response.content))
    # we will display it in notebook 
    return plt.imshow(img)

display_img(data['product_image'][1])
print(data['output'][1])

display_img(data['product_image'][50])
print(data['output'][50])

display_img(data['product_image'][200])
print(data['output'][200])

display_img(data['product_image'][300])
print(data['output'][300])

display_img(data['product_image'][250])
print(data['output'][250])

## downlaod images for these  data points(using id), run once
for idx, row in data.iterrows():
    url = row['product_image']
    response = requests.get(url)
    img = Image.open(BytesIO(response.content))
    img.save('images/'+ str(row['PID'])+'.jpeg')

# creating a function to download the image links from the dataset
def img_array(img):   
    """
    This function takes in an image and converts the image to an array after resizing
  
    """
    response = urllib.request.urlopen(img)
    image = np.asarray(bytearray(response.read()), dtype="uint8") 
    image_bgr = cv2.imdecode(image, cv2.IMREAD_COLOR)
    image_bgr = cv2.resize(image_bgr, (224,224)) # resizing all images to one size 
    return image_bgr

# Using the above function here to store all the images in the dataset into arrays
image_array=[]
for i in data['product_image']:
    image_array.append(img_array(i))
    
img_arr=np.array(image_array)

# Converting the response variable into numbers
data['output'][data['output']=='shoes' ]=0
data['output'][data['output']=='shirts' ]=1
data['output'][data['output']=='bags' ]=2
data['output'][data['output']=='watches' ]=3
data['output'][data['output']=='phone' ]=4
data['output'][data['output']=='earphones' ]=5
data['output'][data['output']=='laptop' ]=6
data['output'][data['output']=='pants' ]=7
data['output'][data['output']=='ring' ]=8
data['output'][data['output']=='necklace' ]=9
data['output'][data['output']=='anklet' ]=10
data['output']=data['output'].astype(int)

from sklearn.model_selection import train_test_split

# Splitting the data
train_images, test_images, train_labels, test_labels=train_test_split(img_arr, data['output'], test_size=0.60, random_state=42)

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

set_seed(42) #setting the seed
cnn = Sequential()

# The convolutional layers
cnn.add(layers.Conv2D(filters = 32, kernel_size = (3, 3), activation='relu', input_shape=train_images[0].shape, kernel_regularizer=regularizers.l1(1e-5)))
cnn.add(layers.MaxPooling2D(pool_size = (2, 2)))
cnn.add(Dropout(.20))
cnn.add(layers.Conv2D(64, (3, 3), activation='relu'))
cnn.add(layers.MaxPooling2D((2, 2)))
cnn.add(Dropout(.20))
cnn.add(layers.Conv2D(32, (3, 3), activation='relu'))
cnn.add(layers.MaxPooling2D((2, 2)))
cnn.add(Dropout(.20))

# The fully connected layers
cnn.add(layers.Flatten())
cnn.add(layers.Dense(32, activation='relu'))
cnn.add(Dropout(.20))
cnn.add(layers.Dense(5, activation='softmax'))

from sklearn.preprocessing import StandardScaler
from tensorflow import keras

# Compile the model
cnn.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])

# Compile the model
model = cnn.fit(train_images, train_labels, epochs=50, validation_split=0.2, # taking 20 percent of training set for validation
                  callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience=10))

# saving it in a '.h5' format file which would be used for the AI Demo during the presentation
cnn.save('model_cnn.h5')

# Prediction on the test image
cnn_pred = cnn.predict(test_images, verbose=1)
cnn_pred = np.argmax(cnn_pred, axis=1) # this will pick the value in an array having the maximum score

plt.plot(model.history['loss'])
plt.plot(model.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Training', 'Validation'], loc='upper right')
plt.show()

print("Accuracy : ", cnn.evaluate(test_images, test_labels))

# Confusion matrix for results
cm = confusion_matrix(test_labels, cnn_pred)

fig, ax= plt.subplots(figsize=(10,10))
sns.heatmap(cm, annot=True, ax = ax, fmt='g'); # annot=True to annotate cells. 'fmt' prevents the numbers from going to scientific notation

# labels, title and ticks
ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['bags','hats','shirts','shoes','watches']); ax.yaxis.set_ticklabels(['bags','hats','shirts','shoes','watches']);

test_labels=test_labels.tolist() # converting the test_labels into a list



# Creating a function which picks random images and identifies the class to which the image belongs

def get_image_and_class(size):

  idx = np.random.randint(len(test_images), size=size) # generating a random image from the test data

  for i in range(len(idx)):

    plt.imshow(test_images[idx,:][i])

    plt.show()

    

  # Print the class of the random image picked above

    if test_labels[idx[i]] == 0:

      print('This is a Shoe!')

    elif test_labels[idx[i]] == 1:

      print('This is a Shirt!')

    elif test_labels[idx[i]] == 2:

      print('This is a Bag!')

    elif test_labels[idx[i]] == 3:

      print('This is a Watch!')

    elif test_labels[idx[i]] == 4:

      print('This is a Phone!')

    elif test_labels[idx[i]] == 5:

      print('This is a Earphone!')

    elif test_labels[idx[i]] == 6:

      print('This is a Laptop!')

    elif test_labels[idx[i]] == 7:

      print('These are Pants!')

    elif test_labels[idx[i]] == 8:

      print('This is a Ring!')

    elif test_labels[idx[i]] == 9:

      print('This is a Necklace!')

    elif test_labels[idx[i]] == 10:

      print('This is an Anklet!')

get_image_and_class(15)

count_vectorize = CountVectorizer(stop_words = 'english') # Initialize the CountVectorizer
title_vectorized = count_vectorize.fit_transform(data['product_name']) # Run the CountVectorizer on the text
title_vectorized.shape

#A representation of the count vectorizer
counts = pd.DataFrame(title_vectorized.toarray(),columns=count_vectorize.get_feature_names())
counts

cosine_sim_user2 = cosine_similarity(title_vectorized, title_vectorized)

cosine_sim_users2_df=pd.DataFrame(cosine_sim_user2)
cosine_sim_users2_df.columns=data['product_name']
cosine_sim_users2_df.index=data['product_name']
cosine_sim_users2_df

def text_recommend_1(pid, num_recommend):
    
    """
    PID: Product ID of the original item in our dataset
    num_recommend : Number of most similar items to retrieve 

    Returns product ID, title, brand and similarity score of the recommended items
    """
    cosine_sim = cosine_similarity(title_vectorized, title_vectorized)

    # initializing the empty list for recommended products and similarity score
    recommended_prod = []
    score=[]
    
    #Displaying the original product- PID, Name, Brand
    
    print("-----------------------------------------------------------------------")
    print("Original product:")
    print("-----------------------------------------------------------------------")
    print("Product ID : " , pid)
    print("Title : ", data['product_name'][data['PID']==pid].item())
    
    # creating a Series with the similarity scores in descending order
    score_series = pd.Series(cosine_sim[pid]).sort_values(ascending = False)

    # getting the indexes and scores of the N most similar products
    top_10_indexes = list(score_series.iloc[1:(num_recommend+1)].index)
    top_10_score=list(score_series.iloc[1:(num_recommend+1)])
    
    # Displaying the recommended products- PID, Name, Brand and Similarity Score
    print("\n")
    print("-----------------------------------------------------------------------")
    print("Most similar products:")
    print("-----------------------------------------------------------------------")
    
    for i in range(0,len(top_10_score)):
      try:
        recommended_prod.append(list(data['product_name'])[i])
      except ValueError:
        continue
      print("\nProduct ID : " , top_10_indexes[i])
      print("Title : ", data['product_name'][data['PID']==top_10_indexes[i]].item())
      #print("Brand : ", data['product_brand'][data['PID']==top_10_indexes[i]].item())
      print("Similarity score : ",top_10_score[i])

text_recommend_1(40,5)

# load the model
vgg_model = vgg16.VGG16(weights='imagenet')

# remove the last layers in order to get features instead of predictions
feat_extractor = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer("fc2").output)

# print the layers of the CNN
feat_extractor.summary()

imgs_path = "images/"
imgs_model_width, imgs_model_height = 224,224

files = [imgs_path + x for x in os.listdir(imgs_path) if "jpeg" in x]

print("number of images:",len(files))

_re_digits = re.compile(r'\d+') #We use regex to extract only the pids from file names
pid = []
for element in files:
    pid += [int(n) for n in _re_digits.findall(element)]

# #We add the pid and the image url to a dataframe
df={'PID':pid,'Images':files}
df=pd.DataFrame(df)

# load all the images and prepare them for feeding into the CNN

importedImages = []

for f in files:
    filename = f
    original = load_img(filename, target_size=(224, 224)) #Set the image size to 224*224
    numpy_image = img_to_array(original) #Convert the images to array
    image_batch = np.expand_dims(numpy_image, axis=0)
    importedImages.append(image_batch)
    
images = np.vstack(importedImages)

processed_imgs = preprocess_input(images.copy())

# extract the images features

imgs_features = feat_extractor.predict(processed_imgs)

print("features successfully extracted!")
imgs_features.shape

# compute cosine similarities between images

cosSimilarities = cosine_similarity(imgs_features)

# store the results into a pandas dataframe

cos_similarities_df = pd.DataFrame(cosSimilarities, columns=files, index=files)
cos_similarities_df

# function to retrieve the most similar products for a given one

def image_recommend_1(pid,num_recommend = 5):
    
    """
    PID: Product ID of the original item in our dataset
    num_recommend : Number of most similar images to retrieve
    
    """
    
    given_img=df['Images'][df['PID']==pid].item()
    
    #Displaying the original product- Image, PID, Name, Brand
    
    print("-----------------------------------------------------------------------")
    print("Original product:")
    print("-----------------------------------------------------------------------")
    
    print("\nProduct ID : ",pid)
    print("Title : ",data['product_name'][data['PID']==pid].item())
    original = load_img(given_img, target_size=(imgs_model_width, imgs_model_height))
    plt.imshow(original)
    plt.show()
    
    # getting the indexes and scores of the N most similar products
    closest_imgs = cos_similarities_df[given_img].sort_values(ascending=False)[1:num_recommend+1].index
    closest_imgs_scores = cos_similarities_df[given_img].sort_values(ascending=False)[1:num_recommend+1]
    
    _re_digits = re.compile(r'\d+') #We use regex to extract only the pids from file names
    closest_imgs_pid = []
    for element in closest_imgs:
        closest_imgs_pid += [int(n) for n in _re_digits.findall(element)]
    
    # Displaying the recommended products- Image, PID, Name, Brand and Similarity Score

    print("-----------------------------------------------------------------------")
    print("Most similar products:")
    print("-----------------------------------------------------------------------") 
    
    
    for i in range(0,len(closest_imgs)):
        print("\nProduct ID : ",closest_imgs_pid[i])
        print("Title : ",data['product_name'][data['PID']==closest_imgs_pid[i]].item())
        #print("Brand : ",data['Product_Brand'][data['PID']==closest_imgs_pid[i]].item())
        print("similarity score : ",closest_imgs_scores[i])
        
        
        original = load_img(closest_imgs[i], target_size=(imgs_model_width, imgs_model_height))
        plt.imshow(original)
        plt.show()

image_recommend_1(20,15)

image_recommend_1(60,5)

image_recommend_1(100,5)